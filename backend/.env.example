# ============================================
# LLM Configuration
# ============================================
OPENAI_API_KEY=your_api_key_here
OPENAI_API_BASE=https://api.openai.com/v1
LLM_MODEL=gpt-4o
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=4096

# ============================================
# Embedding Configuration
# ============================================
EMBEDDING_API_KEY=
EMBEDDING_API_BASE=
EMBEDDING_MODEL=text-embedding-3-small

# ============================================
# Translation Model Configuration
# (Falls back to main LLM config if not set)
# ============================================
TRANSLATE_API_KEY=
TRANSLATE_API_BASE=
TRANSLATE_MODEL=

# ============================================
# Cache Configuration
# ============================================

# Enable/disable caching for different components
ENABLE_URL_CACHE=true
ENABLE_LLM_CACHE=false          # 默认关闭，避免影响 Agent 探索性
ENABLE_PROMPT_CACHE=true
ENABLE_TRANSLATE_CACHE=true

# Cache TTL in seconds
URL_CACHE_TTL=3600              # 1 hour
LLM_CACHE_TTL=86400             # 24 hours
PROMPT_CACHE_TTL=600            # 10 minutes
TRANSLATE_CACHE_TTL=604800      # 7 days

# Memory cache limits
CACHE_MAX_MEMORY_ITEMS=100      # Max items in L1 cache

# Disk cache size limit (MB)
CACHE_MAX_DISK_SIZE_MB=5120     # 5GB
